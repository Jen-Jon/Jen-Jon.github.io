<!DOCTYPE html>
<html lang=""><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>TorchScript教程（译）</title>
    <meta name="description" content="A simple homepage of Jensen Zhang.">
    <meta name="author" content='Jensen Zhang'>

    <link href="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/homepage_css2.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/buttonsstyle.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous">
    
    <script defer src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/backbutton.js"></script>
    <script async src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/busuanzi.pure.mini.js"></script>

    
    <script>
        WIDGET = {
        "CONFIG": {
            "modules": "0124",
            "background": "5",
            "tmpColor": "fff",
            "tmpSize": "16",
            "tmpPadding": "10px",
            "cityColor": "000",
            "citySize": "16",
            "aqiColor": "fff",
            "aqiSize": "16",
            "weatherIconSize": "24",
            "alertIconSize": "18",
            "padding": "0px",
            
            "language": "en",
            "key": "06a49925209149af84e325a6c7e5c521"
        }
        }
    </script>
    <script src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/qweather/he-simple-common-v2.0.2.js"></script>
    

    
    <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?a4cacad7bf6ee4f58534d26d5b23ad14";
          var s = document.getElementsByTagName("script")[0]; 
          s.parentNode.insertBefore(hm, s);
        })();
    </script>
    

    <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.0/fuse.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/bloglayouts/search-v1.3.js"></script>

    
    <script id="search-result-template" type="text/x-js-template">
        <article id="summary-${key}">
            <header>
                <h3><i class="fas fa-file-alt"></i> <a href="${link}">${title}</a></h3>
                <h4>${date} | ${type} blog | ${tags}</h4>
            </header>
            <div>
                <div>${snippet}...</div>
                
                <div class="ReadButton">
                    <a class="read-more-link ReadButton_a" href="https://jen-jon.github.io/posts/20220919/">
                        <strong style="color: #fff;">Read More</strong>
                    </a>
                </div>
                
            </div>
            <hr>
        </article>
    </script>

    
    <link rel="stylesheet" href="/sass/researcher.min.css">

    
        <link rel="icon" type="image/ico" href="https://jen-jon.github.io/images/favicon.ico">
    

    
        
    
</head>

    <body><div id="ukraine" style="background-color: #1f71e0; ">
    <a class="cba fas fa-window-close" onclick="test()" style="display:block; float:right; width:30px; height:29px;" href="#"></a>
    <div style="height: 50px; display: flex; text-align: center; justify-content: center; align-items: center;">
        <div style="margin: 0 10px;">
            <div style="font-size: 45px;">🇺🇦</div>
        </div>
        <div style="margin: 0 10px;">
            <a style="color: white;" href="/we-stand-with-ukraine">
                <div style="color: white; font-weight: bold; font-size: large;">We stand with Ukraine!</div>
                <div style="color: white; font-weight: bold; font-size: large;">我们支持乌克兰！</div>
            </a>
        </div>
    </div>
</div>
<script>
    function test() {
        document.getElementById("ukraine").parentElement.removeChild(document.getElementById("ukraine"));
    }
</script>

<div class="container mt-5" style="text-align: right;">
    
    <div style="display: inline-flex; background-color: #1f71e0;">
        <div style="z-index: 9999;"><div id="he-plugin-simple"></div></div>
    </div>
    
    <nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0">
        <a class="navbar-brand mx-0 mr-sm-auto" href="https://jen-jon.github.io/" title="Jensen&#39;s Homepage">
          
          <i class="fas fa-home"></i>
          Jensen&#39;s Homepage
        </a>
        <div class="navbar-nav flex-row flex-wrap justify-content-center">
            
                
                
                    <a class="nav-item nav-link" href="/about" title="About">
                        About
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="/posts" title="Posts">
                        Posts
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="/mediatest" title="Media">
                        Media
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/Resumes/Resume_of_Jensen.pdf" title="Resume/CV">
                        Resume/CV
                    </a>
                    
                
            
        </div>
    </nav>
</div>
<hr><div id="content">
<div class="container">
    
    <h1 style="color: #1f71e0;">TorchScript教程（译）</h1>
    
    <h5><a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#tracing-modules">Reposted</a> by <a href="https://jen-jon.github.io/">Jensen Zhang</a> on <em>September 19, 2022</em> | <spa id="busuanzi_container_page_pv"><i class="fas fa-eye"></i> <em><span id="busuanzi_value_page_pv"></span></em> readings</span> </h5>
    
    <h5>This article is about <em style="color: #1f71e0;">3517</em> words and may take <em style="color: #1f71e0;">8</em> minutes to read.</h5>
    <hr>
    
    
    <p><img src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/blogstatic/20220919/title.png" alt="Logo"/></p>
    <hr>
    
    
    <blockquote>
        <p><strong>Type: technology blog</strong></p>
        <p><strong>Tags: PyTorch；JIT</strong></p>
    </blockquote>
    <hr>
    
    
    <h1 style="color: #1f71e0;">Content</h1>
    <br>
    
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>__version__
</span></span></code></pre></div><pre><code>'1.8.2'
</code></pre>
<h2 id="编写pytorch模型的基本知识">编写PyTorch模型的基本知识</h2>
<p>我们首先来定义一个简单的<code>Module</code>。<code>Module</code>是PyTorch模型的基本组成单位。其中包含：</p>
<ul>
<li>
<p>一个构造函数，为模块的调用作准备；</p>
</li>
<li>
<p>一组参数和子模块，它们由构造函数初始化，并可由模块在调用期间使用；</p>
</li>
<li>
<p>一个<code>forward</code>函数，这是在调用模块时运行的代码。</p>
</li>
</ul>
<p>来看看下面这个例子：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(x <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell()
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>print(my_cell(x, h))
</span></span></code></pre></div><pre><code>(tensor([[0.5848, 0.6401, 0.5124, 0.6093],
        [0.2706, 0.4608, 0.9002, 0.7638],
        [0.9597, 0.7959, 0.6197, 0.6299]]), tensor([[0.5848, 0.6401, 0.5124, 0.6093],
        [0.2706, 0.4608, 0.9002, 0.7638],
        [0.9597, 0.7959, 0.6197, 0.6299]]))
</code></pre>
<p>从上面代码中可以发现，</p>
<ul>
<li>
<p>创建了一个<code>torch.nn.Module</code>的子类；</p>
</li>
<li>
<p>定义了一个构造函数，并且没有做任何动作除了调用父类<code>super</code>的构造函数；</p>
</li>
<li>
<p>定义了一个<code>forward</code>函数，接收两个输入并返回两个输出；<code>forward</code>函数中的实际内容并不重要，类似于一种假的RNN单元，是一个应用在循环中的函数。</p>
</li>
</ul>
<p>最后，将该类实例化，并创建<code>x</code>和<code>h</code>，它们是3x4的随机矩阵。然后通过<code>my_cell(x, h)</code>调用该实例，同样这也调用了<code>forward</code>函数。</p>
<p>接下来做点更有趣的：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(self<span style="color:#f92672">.</span>linear(x) <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell()
</span></span><span style="display:flex;"><span>print(my_cell)
</span></span><span style="display:flex;"><span>print(my_cell(x, h))
</span></span></code></pre></div><pre><code>MyCell(
  (linear): Linear(in_features=4, out_features=4, bias=True)
)
(tensor([[-0.0131,  0.2256,  0.5951,  0.4361],
        [ 0.0035,  0.7586,  0.6020,  0.0687],
        [ 0.6873,  0.3057,  0.7030,  0.3927]], grad_fn=&lt;TanhBackward&gt;), tensor([[-0.0131,  0.2256,  0.5951,  0.4361],
        [ 0.0035,  0.7586,  0.6020,  0.0687],
        [ 0.6873,  0.3057,  0.7030,  0.3927]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<p>我们重新定义了<code>MyCell</code>模块，但在其中添加了<code>self.linear</code>属性，并在<code>forward</code>函数中调用了<code>self.linear</code>。</p>
<p>这里究竟发生什么了呢？<code>torch.nn.Linear</code>是PyTorch标准库中的<code>Module</code>。正如同<code>MyCell</code>，可以使用调用语法来调用它。我们正在构建一个由<code>Module</code>s组成的层次结构。</p>
<p><code>Module</code>中的<code>print</code>会打印出<code>Module</code>的子类层次结构的直观表示。在我们的示例中，可以看到<code>Linear</code>子类以及其参数。</p>
<p>通过这种方式组合模块，我们能够简洁和高可读地使用可重用组件来编写模型。</p>
<p>你可能会注意到输出结果中的<code>grad_fn</code>，这是PyTorch自动微分的一个细节，称之为<a href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"><code>autograd</code></a>。简而言之，这套系统允许我们通过潜在的复杂程序来计算导数。这种设计增加了模型编写方面的灵活性。</p>
<p>接下来我们来研究一下所谓的灵活性：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyDecisionGate</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> x<span style="color:#f92672">.</span>sum() <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>             <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span>x
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dg <span style="color:#f92672">=</span> MyDecisionGate()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(self<span style="color:#f92672">.</span>dg(self<span style="color:#f92672">.</span>linear(x)) <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell()
</span></span><span style="display:flex;"><span>print(my_cell)
</span></span><span style="display:flex;"><span>print(my_cell(x, h))
</span></span></code></pre></div><pre><code>MyCell(
  (dg): MyDecisionGate()
  (linear): Linear(in_features=4, out_features=4, bias=True)
)
(tensor([[ 0.4873, -0.0183,  0.5451,  0.6425],
        [ 0.1686,  0.3009,  0.6721,  0.3504],
        [ 0.9206,  0.2258,  0.6589,  0.5597]], grad_fn=&lt;TanhBackward&gt;), tensor([[ 0.4873, -0.0183,  0.5451,  0.6425],
        [ 0.1686,  0.3009,  0.6721,  0.3504],
        [ 0.9206,  0.2258,  0.6589,  0.5597]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<p>我们再一次重新定义了<code>MyCell</code>类，但在这里我们定义了<code>MyDecisionGate</code>。这个模块用来<strong>控制流</strong>。控制流由循环和<code>if</code>语句等内容组成。</p>
<p>许多框架采用了计算符号导数的方法，并且给定完整的程序表示。但在PyTorch中，我们使用“梯度胶带”。我们在操作发生时记录它们，并在计算导数回放它们。这样就不必显式地为语言中的所有构造定义导数。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Jen-Jon/CDN_Bank/srcs/blogstatic/20220919/dynamic_graph.gif" alt="How autograd works"></p>
<h2 id="torchscript基础">TorchScript基础</h2>
<p>现在以我们上述示例为例，看看如何使用<code>TorchScript</code>。</p>
<p>简而言之，<code>TorchScript</code>提供了一些工具来捕获模型的定义，甚至考虑到了PyTorch的灵活性和动态性。让我们从被称为<em>tracing</em>的工具来开始探究。</p>
<h3 id="tracing-modules">Tracing <code>Modules</code></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(self<span style="color:#f92672">.</span>linear(x) <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell()
</span></span><span style="display:flex;"><span>x, h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>), torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>traced_cell <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(my_cell, (x, h))
</span></span><span style="display:flex;"><span>print(traced_cell)
</span></span><span style="display:flex;"><span>traced_cell(x, h)
</span></span></code></pre></div><pre><code>MyCell(
  original_name=MyCell
  (linear): Linear(original_name=Linear)
)





(tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
         [-0.1340,  0.6531,  0.3963,  0.8801],
         [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;),
 tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
         [-0.1340,  0.6531,  0.3963,  0.8801],
         [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<p>我们稍微往前回溯了一点，采用<code>MyCell</code>类的第二个版本。和之前一样，我们实例化了它，但这一次我们调用了<code>torch.jit.trace</code>，并将实例化的<code>Module</code>传入，并传入网络中的示例输入。</p>
<p>这个过程中到底发生了什么？它调用了实例化<code>Module</code>，记录了<code>Module</code>运行时发生的操作，并创建了<code>torch.jit.ScriptModule</code>的实例（<code>TracedModule</code>便是其实例）。</p>
<p>TorchScript将其定义记录在中间表示（Intermediate Representation），在深度学习中通常被称为<code>graph</code>。我们可以通过使用<code>.graph</code>属性检查该graph：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(traced_cell<span style="color:#f92672">.</span>graph)
</span></span></code></pre></div><pre><code>graph(%self.1 : __torch__.MyCell,
      %input : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),
      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):
  %21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=&quot;linear&quot;](%self.1)
  %23 : Tensor = prim::CallMethod[name=&quot;forward&quot;](%21, %input)
  %14 : int = prim::Constant[value=1]() # /tmp/ipykernel_18098/4265555285.py:7:0
  %15 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%23, %h, %14) # /tmp/ipykernel_18098/4265555285.py:7:0
  %16 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%15) # /tmp/ipykernel_18098/4265555285.py:7:0
  %17 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%16, %16)
  return (%17)
</code></pre>
<p>然而，这是一种非常<code>low-level</code>的表示，图表中包含的大多数信息对最终用户都没有用处。取而代之的是，可以使用<code>.code</code>属性来提供代码的Python语法解释：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(traced_cell<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    input: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = torch.add((self.linear).forward(input, ), h, alpha=1)
  _1 = torch.tanh(_0)
  return (_1, _1)
</code></pre>
<p>为什么要这样做呢？主要有以下几个原因：</p>
<ul>
<li>
<p>TorchScript代码可以在其自己的解释器中调用，该解释器基本上是一个受限的Python解释器。此解释器不获取全局解释器锁，因此可以在同一实例上同时处理许多请求。</p>
</li>
<li>
<p>此格式允许我们将整个模型保存到磁盘，并将其加载到另一个环境中，例如在用非Python语言编写的服务器中。</p>
</li>
<li>
<p>TorchScript为我们提供了一种表示形式，我们可以在其中对代码进行编译器优化，以提供更高效的执行。</p>
</li>
<li>
<p>TorchScript允许我们与许多后端/设备运行时交互，这些后端/设备运行时需要比单个运算符更广泛的程序视图。</p>
</li>
</ul>
<p>我们可以看到，调用<code>traced_cell</code>会产生与Python模块相同的结果：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(my_cell(x, h))
</span></span><span style="display:flex;"><span>print(traced_cell(x, h))
</span></span></code></pre></div><pre><code>(tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
        [-0.1340,  0.6531,  0.3963,  0.8801],
        [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;), tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
        [-0.1340,  0.6531,  0.3963,  0.8801],
        [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;))
(tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
        [-0.1340,  0.6531,  0.3963,  0.8801],
        [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;), tensor([[-0.6178,  0.1537,  0.2786,  0.4218],
        [-0.1340,  0.6531,  0.3963,  0.8801],
        [-0.7938,  0.7117,  0.6256,  0.6363]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<h3 id="using-scripting-to-convert-modules">Using Scripting to Convert Modules</h3>
<p>上述示例我们使用<code>MyCell</code>的第二个版本而不是带有控制流加载子模块的版本是有原因的，现在我们来探究一下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyDecisionGate</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> x<span style="color:#f92672">.</span>sum() <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span>x
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyCell</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, dg):
</span></span><span style="display:flex;"><span>        super(MyCell, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dg <span style="color:#f92672">=</span> dg
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, h):
</span></span><span style="display:flex;"><span>        new_h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(self<span style="color:#f92672">.</span>dg(self<span style="color:#f92672">.</span>linear(x)) <span style="color:#f92672">+</span> h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_h, new_h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell(MyDecisionGate())
</span></span><span style="display:flex;"><span>traced_cell <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(my_cell, (x, h))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(traced_cell<span style="color:#f92672">.</span>dg<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(traced_cell<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    argument_1: Tensor) -&gt; Tensor:
  return torch.neg(argument_1)

def forward(self,
    input: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = (self.dg).forward((self.linear).forward(input, ), )
  _1 = torch.tanh(torch.add(_0, h, alpha=1))
  return (_1, _1)



/home/jensen/.conda/envs/venv_torch/lib/python3.7/site-packages/ipykernel_launcher.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  This is separate from the ipykernel package so we can avoid doing imports until
</code></pre>
<p>查看<code>.code</code>的输出，可以发现完全找不到<code>if-else</code>的踪迹！WHY?! Tracing所做的正如我们所说的那样，运行代码，记录所发生的操作，并构造一个执行这些操作的<code>ScriptModule</code>。不幸的是，像控制流这样的操作被擦除了。</p>
<p>那如何在TorchScript中准确地表示这个模块？我们提供了一个<strong>script compiler</strong>，它可以直接分析Python源代码，并将其转换为TorchScript。让我们直接使用<strong>script compiler</strong>转换<code>MyDecisionGate</code>：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scripted_gate <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(MyDecisionGate())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>my_cell <span style="color:#f92672">=</span> MyCell(scripted_gate)
</span></span><span style="display:flex;"><span>scripted_cell <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(my_cell)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(scripted_gate<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(scripted_cell<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    x: Tensor) -&gt; Tensor:
  _0 = bool(torch.gt(torch.sum(x, dtype=None), 0))
  if _0:
    _1 = x
  else:
    _1 = torch.neg(x)
  return _1

def forward(self,
    x: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = (self.dg).forward((self.linear).forward(x, ), )
  new_h = torch.tanh(torch.add(_0, h, alpha=1))
  return (new_h, new_h)
</code></pre>
<p>太棒了！我们现在已经准确地捕获了我们的程序在TorchScript中的行为。现在让我们尝试运行该程序：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># New inputs</span>
</span></span><span style="display:flex;"><span>x, h <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>), torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>scripted_cell(x, h)
</span></span></code></pre></div><pre><code>(tensor([[0.7933, 0.2852, 0.3526, 0.0098],
         [0.7790, 0.6442, 0.5631, 0.6060],
         [0.4623, 0.2208, 0.0442, 0.8844]], grad_fn=&lt;TanhBackward&gt;),
 tensor([[0.7933, 0.2852, 0.3526, 0.0098],
         [0.7790, 0.6442, 0.5631, 0.6060],
         [0.4623, 0.2208, 0.0442, 0.8844]], grad_fn=&lt;TanhBackward&gt;))
</code></pre>
<h3 id="混合scripting和tracing">混合Scripting和Tracing</h3>
<p>有些情况下需要使用tracing而不是scripting（例如，模块中含有许多架构决策，这些决策是基于我们不希望出现在TorchScript中常量Python值做出的）。这种情况下，可以将scripting和tracing结合起来使用：<code>torch.jit.script</code>将会内联一个<code>traced</code>模块，tracing将会内联一个<code>scripted</code>模块。</p>
<p>第一种情况的示例：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyRNNLoop</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(MyRNNLoop, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>cell <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(MyCell(scripted_gate), (x, h))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, xs):
</span></span><span style="display:flex;"><span>        h, y <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>), torch<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(xs<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)):
</span></span><span style="display:flex;"><span>            y, h <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>cell(xs[i], h)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> y, h
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>run_loop <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(MyRNNLoop())
</span></span><span style="display:flex;"><span>print(run_loop<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(run_loop<span style="color:#f92672">.</span>cell<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(run_loop<span style="color:#f92672">.</span>cell<span style="color:#f92672">.</span>dg<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    xs: Tensor) -&gt; Tuple[Tensor, Tensor]:
  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)
  y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)
  y0 = y
  h0 = h
  for i in range(torch.size(xs, 0)):
    _0 = (self.cell).forward(torch.select(xs, 0, i), h0, )
    y1, h1, = _0
    y0, h0 = y1, h1
  return (y0, h0)

def forward(self,
    input: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = (self.dg).forward((self.linear).forward(input, ), )
  _1 = torch.tanh(torch.add(_0, h, alpha=1))
  return (_1, _1)

def forward(self,
    x: Tensor) -&gt; Tensor:
  _0 = bool(torch.gt(torch.sum(x, dtype=None), 0))
  if _0:
    _1 = x
  else:
    _1 = torch.neg(x)
  return _1
</code></pre>
<p>第二种情况的例子：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WrapRNN</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(WrapRNN, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>loop <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(MyRNNLoop())
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, xs):
</span></span><span style="display:flex;"><span>        y, h <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>loop(xs)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>relu(y)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>traced <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(WrapRNN(), (torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)))
</span></span><span style="display:flex;"><span>print(traced<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(traced<span style="color:#f92672">.</span>loop<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(traced<span style="color:#f92672">.</span>loop<span style="color:#f92672">.</span>cell<span style="color:#f92672">.</span>code)
</span></span><span style="display:flex;"><span>print(traced<span style="color:#f92672">.</span>loop<span style="color:#f92672">.</span>cell<span style="color:#f92672">.</span>dg<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>def forward(self,
    argument_1: Tensor) -&gt; Tensor:
  _0, y, = (self.loop).forward(argument_1, )
  return torch.relu(y)

def forward(self,
    xs: Tensor) -&gt; Tuple[Tensor, Tensor]:
  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)
  y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)
  y0 = y
  h0 = h
  for i in range(torch.size(xs, 0)):
    _0 = (self.cell).forward(torch.select(xs, 0, i), h0, )
    y1, h1, = _0
    y0, h0 = y1, h1
  return (y0, h0)

def forward(self,
    input: Tensor,
    h: Tensor) -&gt; Tuple[Tensor, Tensor]:
  _0 = (self.dg).forward((self.linear).forward(input, ), )
  _1 = torch.tanh(torch.add(_0, h, alpha=1))
  return (_1, _1)

def forward(self,
    x: Tensor) -&gt; Tensor:
  _0 = bool(torch.gt(torch.sum(x, dtype=None), 0))
  if _0:
    _1 = x
  else:
    _1 = torch.neg(x)
  return _1
</code></pre>
<p>因而，scripting和tracing可以在情况需要时将它们合并在一起使用。</p>
<h3 id="保存和加载模型">保存和加载模型</h3>
<p>我们提供了以存档格式将TorchScript模块保存和加载到磁盘或从磁盘加载的APIs。这种格式包含代码、参数、属性和调试信息，这意味着存档是模型的独立表示形式，可以在完全独立的进程中加载。</p>
<p>接下来让我们保存并加载wrapped RNN模块：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>traced<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;wrapped_rnn.pt&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>loaded <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;wrapped_rnn.pt&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(loaded)
</span></span><span style="display:flex;"><span>print(loaded<span style="color:#f92672">.</span>code)
</span></span></code></pre></div><pre><code>RecursiveScriptModule(
  original_name=WrapRNN
  (loop): RecursiveScriptModule(
    original_name=MyRNNLoop
    (cell): RecursiveScriptModule(
      original_name=MyCell
      (dg): RecursiveScriptModule(original_name=MyDecisionGate)
      (linear): RecursiveScriptModule(original_name=Linear)
    )
  )
)
def forward(self,
    argument_1: Tensor) -&gt; Tensor:
  _0, y, = (self.loop).forward(argument_1, )
  return torch.relu(y)
</code></pre>
<p>如您所见，序列化保留了模块层次结构和我们一直在研究的代码。例如，也可以将模型<a href="https://pytorch.org/tutorials/advanced/cpp_export.html">加载到C++</a>中，以便在不使用Python的情况下执行。</p>
<h2 id="延伸阅读">延伸阅读</h2>
<p>我们已经完成了本教程！有关更复杂的演示，请查看使用TorchScript转换机器翻译模型NeurIPS的演示：</p>
<p><a href="https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ">https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ</a></p>

    <div class="CornerButtons">
        <div class="CornerAnimayedFlex">
            <div class="CornerButton" title="Back to the top">
                <a href="#top" class="cba fas fa-hand-middle-finger" ></a>
            </div>
        </div>
    </div>

<hr>

<h1 style="color: #1f71e0;">Comments</h1>
<script defer src="https://utteranc.es/client.js" 
repo="Jen-Jon/Jen-Jon.github.io" 
issue-term="title" 
theme="github-light" 
crossorigin="anonymous" async></script>


</div>

<h5 style="text-align: center; font-size: large;">This blog is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0</a>, please indicate the source for non-commercial reposted.</h5>


        </div><strong id="footer" class="mb-5">
    <hr>
    
    <div class="container text-center">
        
            <a href="https://github.com/Jen-Jon/" class="fab fa-github fa-1x" title="Github" style="text-decoration: none;"></a>
        
            <a href="https://hub.docker.com/u/ijerry22" class="fab fa-docker fa-1x" title="DockerHub" style="text-decoration: none;"></a>
        
            <a href="https://www.researchgate.net/profile/Jingyao-Zhang-4" class="fab fa-researchgate fa-1x" title="researchgate" style="text-decoration: none;"></a>
        
            <a href="mailto:jensen.acm@gmail.com" class="fas fa-envelope fa-1x" title="E-mail" style="text-decoration: none;"></a>
        
    </div>
    
        <div class="container text-center">
            <h5 class="text-center" style="font-size: small;">Copyright © 2020-2024 <a href="https://github.com/Jen-Jon/" style="color: #1f71e0;" title="Jensen-Jon">Jensen-Jon</a>. All rights reserved.</h5>
        </div>
    
</div>
</body>
</html>
